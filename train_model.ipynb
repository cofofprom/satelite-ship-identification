{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6282850,"sourceType":"datasetVersion","datasetId":3612705}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom lxml import objectify\nimport os\nimport torch\n\nfrom PIL import Image\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import pil_to_tensor\nfrom torchvision.transforms.v2 import functional as F\nfrom torchvision import tv_tensors\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:26:45.246026Z","iopub.execute_input":"2025-01-30T21:26:45.246421Z","iopub.status.idle":"2025-01-30T21:26:45.252092Z","shell.execute_reply.started":"2025-01-30T21:26:45.246389Z","shell.execute_reply":"2025-01-30T21:26:45.250776Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"class HRSC2016(torch.utils.data.Dataset):\n    def __init__(self, root, transforms=None, imageset='train'):\n        self.root = root\n        self.transforms = transforms\n\n        with open(os.path.join(root, \"ImageSets\", f'{imageset}.txt'), 'r') as f:\n            required_imgs = set(f.read().split())\n\n        self.imgs = list(filter(lambda x: x.split('.')[0] in required_imgs, sorted(os.listdir(os.path.join(root, \"AllImages\")))))\n        self.annots = list(filter(lambda x: x.split('.')[0] in required_imgs, sorted(os.listdir(os.path.join(root, \"Annotations\")))))\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root, \"AllImages\", self.imgs[idx])\n        annot_path = os.path.join(self.root, \"Annotations\", self.annots[idx])\n        \n        img = F.pil_to_tensor(Image.open(img_path))\n        with open(annot_path, 'rb') as f:\n            annot_root = objectify.fromstring(f.read())\n\n        num_obj = len(annot_root.object)\n        \n        bbs = []\n        for obj in annot_root.object:\n            bbox_xml = obj.bndbox\n            bbox = [int(bbox_xml.xmin), int(bbox_xml.ymin), int(bbox_xml.xmax), int(bbox_xml.ymax)]\n            bbox = torch.tensor(bbox)\n            bbs.append(bbox)\n\n        bboxes = torch.stack(bbs)\n        areas = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n        \n        bboxes = tv_tensors.BoundingBoxes(bboxes, format='XYXY', canvas_size=F.get_size(img))\n        labels = torch.ones((num_obj,), dtype=torch.int64)\n        iscrowd = torch.zeros((num_obj,), dtype=torch.int64)\n        \n        img = tv_tensors.Image(img)\n        target = dict()\n        target['boxes'] = bboxes\n        target['labels'] = labels\n        target['image_id'] = idx\n        target['area'] = areas\n        target['iscrowd'] = iscrowd\n        \n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:25:14.556021Z","iopub.execute_input":"2025-01-30T21:25:14.556462Z","iopub.status.idle":"2025-01-30T21:25:14.568425Z","shell.execute_reply.started":"2025-01-30T21:25:14.556426Z","shell.execute_reply":"2025-01-30T21:25:14.567304Z"}},"outputs":[],"execution_count":151},{"cell_type":"code","source":"dataset = HRSC2016('/kaggle/input/hrsc2016-ms-dataset', imageset='trainval')\n\nlen(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:25:14.989634Z","iopub.execute_input":"2025-01-30T21:25:14.989981Z","iopub.status.idle":"2025-01-30T21:25:15.004730Z","shell.execute_reply.started":"2025-01-30T21:25:14.989953Z","shell.execute_reply":"2025-01-30T21:25:15.003582Z"}},"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"1070"},"metadata":{}}],"execution_count":152},{"cell_type":"code","source":"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n\nnum_classes = 2  # ship + background\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}